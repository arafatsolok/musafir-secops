package main

import (
	"context"
	"crypto/sha256"
	"encoding/hex"
	"encoding/json"
	"fmt"
	"net"
	"net/http"
	"os"
	"os/signal"
	"strings"
	"sync"
	"syscall"
	"time"

	ch "github.com/ClickHouse/clickhouse-go/v2"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promhttp"
	"github.com/segmentio/kafka-go"
	"go.uber.org/zap"
	"go.uber.org/zap/zapcore"
)

type EmailEvent struct {
	ID          string                 `json:"id"`
	Timestamp   time.Time              `json:"timestamp"`
	MessageID   string                 `json:"message_id"`
	From        string                 `json:"from"`
	To          []string               `json:"to"`
	CC          []string               `json:"cc"`
	BCC         []string               `json:"bcc"`
	Subject     string                 `json:"subject"`
	Body        string                 `json:"body"`
	HTMLBody    string                 `json:"html_body"`
	Attachments []EmailAttachment      `json:"attachments"`
	Headers     map[string]string      `json:"headers"`
	Size        int64                  `json:"size"`
	Direction   string                 `json:"direction"` // inbound, outbound
	Source      string                 `json:"source"`    // m365, gmail, exchange
	Metadata    map[string]interface{} `json:"metadata"`
}

type EmailAttachment struct {
	ID          string                 `json:"id"`
	Name        string                 `json:"name"`
	Size        int64                  `json:"size"`
	ContentType string                 `json:"content_type"`
	Hash        string                 `json:"hash"`
	IsMalicious bool                   `json:"is_malicious"`
	ScanResult  map[string]interface{} `json:"scan_result"`
}

type EmailAlert struct {
	ID          string                 `json:"id"`
	Timestamp   time.Time              `json:"timestamp"`
	AlertType   string                 `json:"alert_type"`
	Severity    string                 `json:"severity"`
	MessageID   string                 `json:"message_id"`
	From        string                 `json:"from"`
	To          []string               `json:"to"`
	Subject     string                 `json:"subject"`
	Description string                 `json:"description"`
	IOCs        []string               `json:"iocs"`
	TTPs        []string               `json:"ttps"`
	Confidence  float64                `json:"confidence"`
	Metadata    map[string]interface{} `json:"metadata"`
}

type EmailThreat struct {
	ID          string                 `json:"id"`
	Timestamp   time.Time              `json:"timestamp"`
	ThreatType  string                 `json:"threat_type"`
	Severity    string                 `json:"severity"`
	MessageID   string                 `json:"message_id"`
	From        string                 `json:"from"`
	To          []string               `json:"to"`
	Subject     string                 `json:"subject"`
	Description string                 `json:"description"`
	IOCs        []string               `json:"iocs"`
	TTPs        []string               `json:"ttps"`
	Confidence  float64                `json:"confidence"`
	Action      string                 `json:"action"` // quarantine, delete, allow
	Metadata    map[string]interface{} `json:"metadata"`
}

type EmailConfig struct {
	Source   string                 `json:"source"`
	Enabled  bool                   `json:"enabled"`
	Config   map[string]interface{} `json:"config"`
	LastSync time.Time              `json:"last_sync"`
	Status   string                 `json:"status"`
}

// Metrics for monitoring
var (
	emailsProcessed = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "email_service_emails_processed_total",
			Help: "Total number of emails processed by type",
		},
		[]string{"direction", "source"},
	)
	
	emailAlerts = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "email_service_alerts_generated_total",
			Help: "Total number of email alerts generated by type and severity",
		},
		[]string{"alert_type", "severity"},
	)
	
	processingErrors = prometheus.NewCounterVec(
		prometheus.CounterOpts{
			Name: "email_service_processing_errors_total",
			Help: "Total number of errors encountered during email processing",
		},
		[]string{"error_type"},
	)
	
	serviceHealth = prometheus.NewGauge(
		prometheus.GaugeOpts{
			Name: "email_service_health",
			Help: "Health status of the email service (1 = healthy, 0 = unhealthy)",
		},
	)
)

func init() {
	// Register metrics with Prometheus
	prometheus.MustRegister(emailsProcessed)
	prometheus.MustRegister(emailAlerts)
	prometheus.MustRegister(processingErrors)
	prometheus.MustRegister(serviceHealth)
	
	// Set initial health status
	serviceHealth.Set(1)
}

func main() {
	// Initialize structured logging
	logConfig := zap.NewProductionConfig()
	logConfig.EncoderConfig.TimeKey = "timestamp"
	logConfig.EncoderConfig.EncodeTime = zapcore.ISO8601TimeEncoder
	
	logger, err := logConfig.Build()
	if err != nil {
		fmt.Fprintf(os.Stderr, "Failed to initialize logger: %v\n", err)
		os.Exit(1)
	}
	defer logger.Sync()
	
	// Replace global logger
	zap.ReplaceGlobals(logger)
	
	logger.Info("Email service starting up")
	
	kbrokers := os.Getenv("KAFKA_BROKERS")
	if kbrokers == "" {
		kbrokers = "localhost:9092"
		logger.Warn("KAFKA_BROKERS not set, using default", zap.String("brokers", kbrokers))
	}
	
	group := os.Getenv("KAFKA_GROUP")
	if group == "" {
		group = "email"
		logger.Warn("KAFKA_GROUP not set, using default", zap.String("group", group))
	}

	chDsn := os.Getenv("CLICKHOUSE_DSN")
	if chDsn == "" {
		chDsn = "tcp://localhost:9000?database=default"
		logger.Warn("CLICKHOUSE_DSN not set, using default", zap.String("dsn", chDsn))
	}

	ctx, cancel := context.WithCancel(context.Background())
	defer cancel()

	// Handle OS signals for graceful shutdown
	shutdownCh := make(chan os.Signal, 1)
	signal.Notify(shutdownCh, syscall.SIGINT, syscall.SIGTERM)
	go func() {
		sig := <-shutdownCh
		logger.Info("Email service shutdown signal received", zap.String("signal", sig.String()))
		serviceHealth.Set(0) // Mark service as unhealthy during shutdown
		cancel()
	}()

	// Connect to ClickHouse with proper error handling
	logger.Info("Connecting to ClickHouse")
	conn, err := ch.Open(&ch.Options{
		Addr: []string{"localhost:9000"},
		Auth: ch.Auth{
			Database: "default",
			Username: os.Getenv("CLICKHOUSE_USER"),
			Password: os.Getenv("CLICKHOUSE_PASSWORD"),
		},
		Settings: ch.Settings{
			"max_execution_time": 60,
		},
		DialTimeout:     5 * time.Second,
		MaxOpenConns:    10,
		MaxIdleConns:    5,
		ConnMaxLifetime: 1 * time.Hour,
	})
	
	if err != nil {
		logger.Error("Failed to connect to ClickHouse", zap.Error(err))
		processingErrors.With(prometheus.Labels{"error_type": "clickhouse_connection"}).Inc()
		os.Exit(1)
	}
	defer conn.Close()
	
	// Ping to verify connection
	if pingErr := conn.Ping(ctx); pingErr != nil {
		logger.Error("Failed to ping ClickHouse", zap.Error(pingErr))
		processingErrors.With(prometheus.Labels{"error_type": "clickhouse_ping"}).Inc()
		os.Exit(1)
	}
	
	logger.Info("Successfully connected to ClickHouse")

	// Ensure email tables exist with retry and proper error handling
	logger.Info("Creating email tables")
	err = retryWithBackoff(ctx, 3, 2*time.Second, func() error {
		if createErr := createEmailTables(conn, ctx); createErr != nil {
			logger.Error("Failed to create email tables", zap.Error(createErr))
			processingErrors.With(prometheus.Labels{"error_type": "table_creation"}).Inc()
			return createErr
		}
		return nil
	})
	
	if err != nil {
		logger.Error("Failed to create email tables after retries", zap.Error(err))
		os.Exit(1)
	}
	
	logger.Info("Email tables created successfully")

	// Start HTTP health/metrics server
	httpServer := startHTTPServer(":8097")
	defer func() {
		ctxShutdown, c := context.WithTimeout(context.Background(), 5*time.Second)
		defer c()
		_ = httpServer.Shutdown(ctxShutdown)
	}()

	// Kafka dialer with timeouts
	dialer := &kafka.Dialer{
		Timeout:   10 * time.Second,
		DualStack: true,
		Resolver:  &net.Resolver{},
	}

	// Event reader with tuned settings
	reader := kafka.NewReader(kafka.ReaderConfig{
		Brokers:         strings.Split(kbrokers, ","),
		Topic:           "musafir.events",
		GroupID:         group,
		Dialer:          dialer,
		MinBytes:        1,
		MaxBytes:        10e6,
		MaxWait:         500 * time.Millisecond,
		ReadLagInterval: 5 * time.Second,
	})
	defer reader.Close()

	// Alert writer with RequiredAcks and Balancer
	writer := kafka.NewWriter(kafka.WriterConfig{
		Brokers:      strings.Split(kbrokers, ","),
		Topic:        "musafir.email_alerts",
		Dialer:       dialer,
		RequiredAcks: int(kafka.RequireAll),
		Balancer:     &kafka.LeastBytes{},
		Async:        false,
		BatchTimeout: 200 * time.Millisecond,
	})
	defer writer.Close()

	// DLQ writer
	dlqWriter := kafka.NewWriter(kafka.WriterConfig{
		Brokers:      strings.Split(kbrokers, ","),
		Topic:        "musafir.dlq.email",
		Dialer:       dialer,
		RequiredAcks: int(kafka.RequireAll),
		Balancer:     &kafka.Hash{},
	})
	defer dlqWriter.Close()

	// Initialize email configurations
	configs := initializeEmailConfigs()

	// Idempotency cache for processed messages
	var (
		seenMu   sync.Mutex
		seenHash = make(map[string]time.Time)
	)
	cleanupTicker := time.NewTicker(10 * time.Minute)
	defer cleanupTicker.Stop()
	go func() {
		for range cleanupTicker.C {
			seenMu.Lock()
			cutoff := time.Now().Add(-15 * time.Minute)
			for h, t := range seenHash {
				if t.Before(cutoff) {
					delete(seenHash, h)
				}
			}
			seenMu.Unlock()
		}
	}()

	logger.Info("Email service consuming events", zap.String("brokers", kbrokers))
	for {
		select {
		case <-ctx.Done():
			logger.Info("Email service shutting down consumer loop")
			return
		default:
			m, err := reader.ReadMessage(ctx)
			if err != nil {
				if ctx.Err() != nil {
					return
				}
				logger.Error("Failed to read from Kafka", zap.Error(err))
				processingErrors.With(prometheus.Labels{"error_type": "kafka_read"}).Inc()
				continue
			}

			// Idempotency check by message hash
			h := sha256.Sum256(m.Value)
			hs := hex.EncodeToString(h[:])
			seenMu.Lock()
			if _, exists := seenHash[hs]; exists {
				seenMu.Unlock()
				continue
			}
			seenHash[hs] = time.Now()
			seenMu.Unlock()

			var event map[string]interface{}
			if err := json.Unmarshal(m.Value, &event); err != nil {
				logger.Error("Failed to unmarshal event", zap.Error(err))
				processingErrors.With(prometheus.Labels{"error_type": "unmarshal_error"}).Inc()
				publishDLQ(ctx, dlqWriter, m.Value, "unmarshal_error")
				continue
			}

			// Process email event with retry; on persistent failure send to DLQ
			procErr := retryWithBackoff(ctx, 3, 300*time.Millisecond, func() error {
				processEmailEvent(event, writer, ctx)
				return nil
			})
			if procErr != nil {
				publishDLQ(ctx, dlqWriter, m.Value, "processing_failed")
			}

			// Monitor email sources (no DLQ)
			go monitorEmailSources(configs, writer, ctx)
		}
	}
}

func startHTTPServer(addr string) *http.Server {
	mux := http.NewServeMux()
	mux.Handle("/metrics", promhttp.Handler())
	mux.HandleFunc("/health", func(w http.ResponseWriter, r *http.Request) {
		w.WriteHeader(http.StatusOK)
		w.Write([]byte("OK"))
	})
	server := &http.Server{
		Addr:         addr,
		Handler:      mux,
		ReadTimeout:  10 * time.Second,
		WriteTimeout: 10 * time.Second,
		IdleTimeout:  60 * time.Second,
	}
	zap.L().Info("Email service HTTP server starting", zap.String("address", addr))
	go func() {
		if err := server.ListenAndServe(); err != nil && err != http.ErrServerClosed {
			zap.L().Error("HTTP server error", zap.Error(err))
			processingErrors.With(prometheus.Labels{"error_type": "http_server"}).Inc()
		}
	}()
	return server
}

func createEmailTables(conn ch.Conn, ctx context.Context) error {
	logger := zap.L()
	logger.Info("Creating email events table")
	
	// Email events table
	ddl := `CREATE TABLE IF NOT EXISTS musafir_email_events (
  id String,
  timestamp DateTime,
  message_id String,
  from_address String,
  to_addresses Array(String),
  cc_addresses Array(String),
  bcc_addresses Array(String),
  subject String,
  body String,
  html_body String,
  attachments String,
  headers String,
  size Int64,
  direction String,
  source String,
  metadata String
) ENGINE = MergeTree ORDER BY timestamp`

	if err := conn.Exec(ctx, ddl); err != nil {
		logger.Error("Failed to create email events table", zap.Error(err))
		return fmt.Errorf("failed to create email events table: %w", err)
	}

	// Email alerts table
	ddl2 := `CREATE TABLE IF NOT EXISTS musafir_email_alerts (
  id String,
  timestamp DateTime,
  alert_type String,
  severity String,
  message_id String,
  from_address String,
  to_addresses Array(String),
  subject String,
  description String,
  iocs Array(String),
  ttps Array(String),
  confidence Float64,
  metadata String
) ENGINE = MergeTree ORDER BY timestamp`

	if err := conn.Exec(ctx, ddl2); err != nil {
		return fmt.Errorf("failed to create email alerts table: %w", err)
	}

	// Email threats table
	ddl3 := `CREATE TABLE IF NOT EXISTS musafir_email_threats (
  id String,
  timestamp DateTime,
  threat_type String,
  severity String,
  message_id String,
  from_address String,
  to_addresses Array(String),
  subject String,
  description String,
  iocs Array(String),
  ttps Array(String),
  confidence Float64,
  action String,
  metadata String
) ENGINE = MergeTree ORDER BY timestamp`

	if err := conn.Exec(ctx, ddl3); err != nil {
		return fmt.Errorf("failed to create email threats table: %w", err)
	}

	// Email configurations table
	ddl4 := `CREATE TABLE IF NOT EXISTS musafir_email_configs (
  source String,
  enabled UInt8,
  config String,
  last_sync DateTime,
  status String
) ENGINE = MergeTree ORDER BY source`

	if err := conn.Exec(ctx, ddl4); err != nil {
		return fmt.Errorf("failed to create email configs table: %w", err)
	}

	return nil
}

func processEmailEvent(event map[string]interface{}, writer *kafka.Writer, ctx context.Context) {
	// Extract email data from event
	emailEvent := extractEmailData(event)

	// Store email event
	storeEmailEvent(emailEvent)

	// Analyze for email threats
	threats := analyzeEmailThreats(emailEvent)

	// Send threats as alerts
	for _, threat := range threats {
		alert := EmailAlert{
			ID:          generateEmailAlertID(),
			Timestamp:   time.Now(),
			AlertType:   threat.ThreatType,
			Severity:    threat.Severity,
			MessageID:   threat.MessageID,
			From:        threat.From,
			To:          threat.To,
			Subject:     threat.Subject,
			Description: threat.Description,
			IOCs:        threat.IOCs,
			TTPs:        threat.TTPs,
			Confidence:  threat.Confidence,
			Metadata:    threat.Metadata,
		}

		alertData, _ := json.Marshal(alert)
		if err := writer.WriteMessages(ctx, kafka.Message{Value: alertData}); err != nil {
			zap.L().Error("Failed to write email alert", zap.Error(err))
			processingErrors.With(prometheus.Labels{"error_type": "kafka_write"}).Inc()
		} else {
			zap.L().Info("Email alert generated", 
				zap.String("alert_type", alert.AlertType),
				zap.String("from", alert.From),
				zap.String("severity", alert.Severity))
		}
	}
}

func extractEmailData(event map[string]interface{}) EmailEvent {
	emailEvent := EmailEvent{
		ID:        generateEmailEventID(),
		Timestamp: time.Now(),
		Metadata:  make(map[string]interface{}),
	}

	// Extract email data from event
	if eventData, ok := event["event"].(map[string]interface{}); ok {
		if attrs, ok := eventData["attrs"].(map[string]interface{}); ok {
			emailEvent.MessageID = getString(attrs, "message_id")
			emailEvent.From = getString(attrs, "from")
			emailEvent.To = getStringArray(attrs, "to")
			emailEvent.CC = getStringArray(attrs, "cc")
			emailEvent.BCC = getStringArray(attrs, "bcc")
			emailEvent.Subject = getString(attrs, "subject")
			emailEvent.Body = getString(attrs, "body")
			emailEvent.HTMLBody = getString(attrs, "html_body")
			emailEvent.Size = getInt64(attrs, "size")
			emailEvent.Direction = getString(attrs, "direction")
			emailEvent.Source = getString(attrs, "source")
		}
	}

	return emailEvent
}

func analyzeEmailThreats(event EmailEvent) []EmailThreat {
	var threats []EmailThreat

	// Check for phishing
	if isPhishingEmail(event) {
		threat := EmailThreat{
			ID:          generateEmailThreatID(),
			Timestamp:   time.Now(),
			ThreatType:  "phishing",
			Severity:    "high",
			MessageID:   event.MessageID,
			From:        event.From,
			To:          event.To,
			Subject:     event.Subject,
			Description: "Phishing email detected",
			IOCs:        []string{event.From, event.Subject},
			TTPs:        []string{"T1566", "T1598"},
			Confidence:  0.85,
			Action:      "quarantine",
			Metadata: map[string]interface{}{
				"phishing_indicators": []string{"urgent", "verify", "account"},
				"sender_reputation":   "suspicious",
			},
		}
		threats = append(threats, threat)
	}

	// Check for malware attachments
	if hasMaliciousAttachments(event) {
		threat := EmailThreat{
			ID:          generateEmailThreatID(),
			Timestamp:   time.Now(),
			ThreatType:  "malware",
			Severity:    "critical",
			MessageID:   event.MessageID,
			From:        event.From,
			To:          event.To,
			Subject:     event.Subject,
			Description: "Malicious attachment detected",
			IOCs:        []string{event.From, event.Subject},
			TTPs:        []string{"T1566.001", "T1204.002"},
			Confidence:  0.95,
			Action:      "quarantine",
			Metadata: map[string]interface{}{
				"malware_type": "trojan",
				"file_hash":    "sha256:abcd1234...",
			},
		}
		threats = append(threats, threat)
	}

	// Check for business email compromise
	if isBusinessEmailCompromise(event) {
		threat := EmailThreat{
			ID:          generateEmailThreatID(),
			Timestamp:   time.Now(),
			ThreatType:  "bec",
			Severity:    "high",
			MessageID:   event.MessageID,
			From:        event.From,
			To:          event.To,
			Subject:     event.Subject,
			Description: "Business email compromise detected",
			IOCs:        []string{event.From, event.Subject},
			TTPs:        []string{"T1566.002", "T1598.002"},
			Confidence:  0.8,
			Action:      "quarantine",
			Metadata: map[string]interface{}{
				"bec_indicators":  []string{"urgent", "wire transfer", "confidential"},
				"sender_spoofing": true,
			},
		}
		threats = append(threats, threat)
	}

	// Check for data exfiltration
	if isDataExfiltration(event) {
		threat := EmailThreat{
			ID:          generateEmailThreatID(),
			Timestamp:   time.Now(),
			ThreatType:  "data_exfiltration",
			Severity:    "high",
			MessageID:   event.MessageID,
			From:        event.From,
			To:          event.To,
			Subject:     event.Subject,
			Description: "Potential data exfiltration detected",
			IOCs:        []string{event.From, event.Subject},
			TTPs:        []string{"T1041", "T1048"},
			Confidence:  0.75,
			Action:      "quarantine",
			Metadata: map[string]interface{}{
				"exfiltration_indicators": []string{"large_attachment", "external_recipient"},
				"data_sensitivity":        "high",
			},
		}
		threats = append(threats, threat)
	}

	return threats
}

func isPhishingEmail(event EmailEvent) bool {
	// Check for phishing indicators in subject and body
	phishingKeywords := []string{
		"urgent", "verify", "account", "suspended", "expired",
		"click here", "verify now", "act now", "limited time",
	}

	subject := strings.ToLower(event.Subject)
	body := strings.ToLower(event.Body)

	for _, keyword := range phishingKeywords {
		if strings.Contains(subject, keyword) || strings.Contains(body, keyword) {
			return true
		}
	}

	return false
}

func hasMaliciousAttachments(event EmailEvent) bool {
	// Check for malicious file types
	maliciousExtensions := []string{
		".exe", ".bat", ".cmd", ".scr", ".pif", ".com",
		".js", ".vbs", ".jar", ".zip", ".rar", ".7z",
	}

	for _, attachment := range event.Attachments {
		for _, ext := range maliciousExtensions {
			if strings.HasSuffix(strings.ToLower(attachment.Name), ext) {
				return true
			}
		}
	}

	return false
}

func isBusinessEmailCompromise(event EmailEvent) bool {
	// Check for BEC indicators
	becKeywords := []string{
		"wire transfer", "urgent payment", "confidential",
		"CEO", "CFO", "executive", "board meeting",
	}

	subject := strings.ToLower(event.Subject)
	body := strings.ToLower(event.Body)

	for _, keyword := range becKeywords {
		if strings.Contains(subject, keyword) || strings.Contains(body, keyword) {
			return true
		}
	}

	return false
}

func isDataExfiltration(event EmailEvent) bool {
	// Check for data exfiltration indicators
	return event.Size > 10*1024*1024 && // Large email
		len(event.Attachments) > 0 && // Has attachments
		isExternalRecipient(event.To) // Sent to external recipients
}

func isExternalRecipient(recipients []string) bool {
	// Check if any recipient is external
	for _, recipient := range recipients {
		if !strings.Contains(recipient, "@company.com") {
			return true
		}
	}
	return false
}

func initializeEmailConfigs() []EmailConfig {
	return []EmailConfig{
		{
			Source:   "m365",
			Enabled:  true,
			LastSync: time.Now(),
			Status:   "active",
			Config: map[string]interface{}{
				"tenant_id":     "tenant-123",
				"client_id":     "client-456",
				"client_secret": "secret-789",
				"endpoint":      "https://graph.microsoft.com",
			},
		},
		{
			Source:   "gmail",
			Enabled:  true,
			LastSync: time.Now(),
			Status:   "active",
			Config: map[string]interface{}{
				"credentials_file": "/path/to/credentials.json",
				"scopes":           []string{"https://www.googleapis.com/auth/gmail.readonly"},
			},
		},
		{
			Source:   "exchange",
			Enabled:  true,
			LastSync: time.Now(),
			Status:   "active",
			Config: map[string]interface{}{
				"server":   "mail.company.com",
				"username": "security@company.com",
				"password": "password123",
			},
		},
	}
}

func monitorEmailSources(configs []EmailConfig, writer *kafka.Writer, ctx context.Context) {
	ticker := time.NewTicker(5 * time.Minute)
	defer ticker.Stop()

	for range ticker.C {
		for _, config := range configs {
			if config.Enabled {
				// Simulate email source monitoring
				if time.Since(config.LastSync) > 10*time.Minute {
					// Source is not syncing
					alert := EmailAlert{
						ID:          generateEmailAlertID(),
						Timestamp:   time.Now(),
						AlertType:   "source_sync_failed",
						Severity:    "medium",
						MessageID:   "",
						From:        "",
						To:          []string{},
						Subject:     "",
						Description: "Email source sync failed",
						IOCs:        []string{config.Source},
						TTPs:        []string{},
						Confidence:  1.0,
						Metadata: map[string]interface{}{
							"source":    config.Source,
							"last_sync": config.LastSync,
						},
					}

					alertData, _ := json.Marshal(alert)
					if err := writer.WriteMessages(ctx, kafka.Message{Value: alertData}); err != nil {
						zap.L().Error("Failed to write source alert", 
							zap.Error(err),
							zap.String("source", config.Source))
						processingErrors.With(prometheus.Labels{"error_type": "kafka_write"}).Inc()
					}
				}
			}
		}
	}
}

func storeEmailEvent(event EmailEvent) {
	// Store email event in ClickHouse
	// Implementation would store the event in the database
}

// Helper functions
func generateEmailEventID() string {
	return "email-" + time.Now().Format("20060102150405")
}

func generateEmailAlertID() string {
	return "email-alert-" + time.Now().Format("20060102150405")
}

func generateEmailThreatID() string {
	return "email-threat-" + time.Now().Format("20060102150405")
}

func getString(data map[string]interface{}, key string) string {
	if val, ok := data[key].(string); ok {
		return val
	}
	return ""
}

func getStringArray(data map[string]interface{}, key string) []string {
	if val, ok := data[key].([]interface{}); ok {
		result := make([]string, len(val))
		for i, v := range val {
			if str, ok := v.(string); ok {
				result[i] = str
			}
		}
		return result
	}
	return []string{}
}

func getInt64(data map[string]interface{}, key string) int64 {
	if val, ok := data[key].(float64); ok {
		return int64(val)
	}
	return 0
}

// retryWithBackoff executes fn up to attempts with exponential backoff starting at base.
func retryWithBackoff(ctx context.Context, attempts int, base time.Duration, fn func() error) error {
	var err error
	for i := 0; i < attempts; i++ {
		if ctx.Err() != nil {
			return ctx.Err()
		}
		err = fn()
		if err == nil {
			return nil
		}
		sleep := time.Duration(1<<i) * base
		timer := time.NewTimer(sleep)
		select {
		case <-ctx.Done():
			return ctx.Err()
		case <-timer.C:
		}
	}
	return err
}

func publishDLQ(ctx context.Context, w *kafka.Writer, payload []byte, reason string) {
	msg := map[string]interface{}{
		"reason":    reason,
		"timestamp": time.Now().Format(time.RFC3339),
		"payload":   string(payload),
	}
	data, _ := json.Marshal(msg)
	_ = w.WriteMessages(ctx, kafka.Message{Value: data})
}
